<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Project AIR â€“ User Guide</title>
    <link>https://tibcosoftware.github.io/labs-air/docs/userguide/</link>
    <description>Recent content in User Guide on Project AIR</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 05 Nov 2021 00:00:00 +0000</lastBuildDate>
    
	  <atom:link href="https://tibcosoftware.github.io/labs-air/docs/userguide/index.xml" rel="self" type="application/rss+xml" />
    
    
      
        
      
    
    
    <item>
      <title>Docs: Configuring Endpoints</title>
      <link>https://tibcosoftware.github.io/labs-air/docs/userguide/configuringendpoints/</link>
      <pubDate>Mon, 25 May 2020 12:33:17 -0400</pubDate>
      
      <guid>https://tibcosoftware.github.io/labs-air/docs/userguide/configuringendpoints/</guid>
      <description>
        
        
        &lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Once a Device Grouping has been discovered by project AIR, a connection has been established with edge devices.
In this section we show how to configure Messaging Protocos, Data Stores and ML Model connections which can be used in Data Pipelines to receive, process data from devices, and publish device data to other edge or cloud applications.
The following steps will guide you through the configuration of messaging protocols, data stores and ML models connections.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;h4 id=&#34;prerequisite-1-edgex&#34;&gt;Prerequisite 1: Edgex&lt;/h4&gt;
&lt;p&gt;Edgex is a vendor neutral open source platform at the edge of the network that interacts with physical devices, sensors, actuators and other IoT objects. It enables the interoperability between devices and applications at the edge and at the cloud.
Edgex will be installed as part of the AIR installation.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;edgexfoundry.org&#34;&gt;Edgex&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Every running Edgex platform uses an internal messaging bus to move data through the different layers at the edge. From a running instance of Edgex, gather the following information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transport used: MQTT, ZeroMQ or Redis&lt;/li&gt;
&lt;li&gt;Connection URL&lt;/li&gt;
&lt;li&gt;Connection credentials&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;prerequisite-2-air&#34;&gt;Prerequisite 2: AIR&lt;/h4&gt;
&lt;p&gt;Project AIR installation provides a messaging broker for sending data from edge devices to wherever the AIR infrastructure is running (in premise, cloud).  The messaging infrastructure is used by AIR core components and also can be used by any application requiring to receive data from edge devices and data flows.&lt;/p&gt;
&lt;p&gt;From a running AIR installation, gather the following information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Transport used: MQTT, Kafka or TCM&lt;/li&gt;
&lt;li&gt;Connection URL&lt;/li&gt;
&lt;li&gt;Connection credentials&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;prerequisite-3-data-store-information&#34;&gt;Prerequisite 3: Data Store Information&lt;/h4&gt;
&lt;p&gt;Device data can be stored in one or several data stores depending on the use case requirements. Gather the following information for each data store:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Connection URL&lt;/li&gt;
&lt;li&gt;Connection Credentials&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;prerequisite-3-data-store-table-setup&#34;&gt;Prerequisite 3: Data Store Table Setup&lt;/h4&gt;
&lt;p&gt;For each required data store, the user needs to configure the data store and create tables to store the data. 
Project AIR provides scripts with SQL commands to create the required artifacts.&lt;/p&gt;
&lt;p&gt;Following is an example sql script to create the artifact for a Postgres Database.
&lt;a href=&#34;./setup.sql&#34;&gt;Postgres SQL script&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;accessing-endpoints-configuration&#34;&gt;Accessing Endpoints Configuration&lt;/h2&gt;
&lt;h4 id=&#34;step-1-from-the-gateways-page-select-the-device-group-you-want-to-configure&#34;&gt;Step 1: From the Gateways page, select the Device Group you want to configure.&lt;/h4&gt;
&lt;h4 id=&#34;step-2-click-the-endpoints-configuration-icon&#34;&gt;Step 2: Click the Endpoints Configuration Icon.&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_endpoint_gateway.png&#34; alt=&#34;Gateway Endpoint Config image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-3-the-endpoint-configuration-page-should-be-displayed&#34;&gt;Step 3: The Endpoint configuration page should be displayed.&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_endpoint.png&#34; alt=&#34;Gateway Endpoint Config image&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;adding-messaging-protocols&#34;&gt;Adding Messaging Protocols&lt;/h2&gt;
&lt;h4 id=&#34;step-1-select-the-desired-protocol-from-the-pulldown-menu-under-the-protocol-details-panel&#34;&gt;Step 1: Select the desired protocol from the pulldown menu under the Protocol Details panel&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_mqtt_1.png&#34; alt=&#34;Adding Protocol MQTT1 image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-2-enter-required-information-for-the-selected-protocol&#34;&gt;Step 2: Enter required information for the selected protocol&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_mqtt_2.png&#34; alt=&#34;Adding Protocol MQTT2 image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-2-click-the-add-protocol-button-the-new-protocol-configuration-should-be-shown-in-the-inbound-protocols-panel&#34;&gt;Step 2: Click the Add Protocol button. The new protocol configuration should be shown in the Inbound Protocols panel&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_mqtt_3.png&#34; alt=&#34;Adding Protocol MQTT2 image&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;adding-data-stores&#34;&gt;Adding Data Stores&lt;/h2&gt;
&lt;h4 id=&#34;step-1-click-the-data-stores-tab&#34;&gt;Step 1: Click the Data Stores tab&lt;/h4&gt;
&lt;h4 id=&#34;step-2-select-the-desired-data-store-from-the-pulldown-menu-under-the-datastore-details-panel&#34;&gt;Step 2: Select the desired data store from the pulldown menu under the DataStore Details panel&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_postgres_1.png&#34; alt=&#34;Adding Postgres1 image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-3-enter-required-information-for-the-selected-data-store&#34;&gt;Step 3: Enter required information for the selected data store&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_postgres_2.png&#34; alt=&#34;Adding Postgres2 image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-4-click-the-add-data-store-button-the-new-data-store-configuration-should-be-shown-in-the-data-stores-panel&#34;&gt;Step 4: Click the Add Data Store button. The new data store configuration should be shown in the Data Stores panel&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_postgres_3.png&#34; alt=&#34;Adding Postgres3 image&#34;&gt;&lt;/p&gt;
&lt;p&gt;Note that before using the data store in a pipeline, the AIR required tables need to be setup.  Project AIR provides scripts for the creation of the required tables for all the different data stores.  See pre-requisites section for details.&lt;/p&gt;
&lt;h2 id=&#34;adding-ml-model-connections&#34;&gt;Adding ML Model Connections&lt;/h2&gt;
&lt;h4 id=&#34;step-1-click-the-models-tab&#34;&gt;Step 1: Click the Models tab&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_models_1.png&#34; alt=&#34;Adding Models1 image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-2-enter-the-model-information-under-the-model-details-panel&#34;&gt;Step 2: Enter the model information under the Model Details panel&lt;/h4&gt;
&lt;p&gt;Scope: select either GLOBAL or GATEWAY:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GLOBAL means the connection will be available and visible to all the pipeline configuration across&lt;/li&gt;
&lt;li&gt;GATEWAY means the connection will be visible only to the pipelines in the current gateway.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Name: is the name of the model connection&lt;/p&gt;
&lt;p&gt;URL: is the address of the model&amp;rsquo;s REST interface.&lt;/p&gt;
&lt;p&gt;Input Template: allow users to provide a json schema definition of the input the model is expecting.  Project air provides template keys that allow device data to be mapped to the required fields in the model.&lt;/p&gt;
&lt;p&gt;Description: allow users to provide a description of what the model does.  This information will be available to users when configuring pipelines.&lt;/p&gt;
&lt;h4 id=&#34;step-3-enter-required-information-for-the-model-connection&#34;&gt;Step 3: Enter required information for the model connection&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_models_2.png&#34; alt=&#34;Adding Models2 image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-4-click-the-add-model-button-the-new-model-connection-configuration-should-be-shown-in-the-models-panel&#34;&gt;Step 4: Click the Add Model button. The new model connection configuration should be shown in the Models panel&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_models_3.png&#34; alt=&#34;Adding Models3 image&#34;&gt;&lt;/p&gt;

      </description>
    </item>
    
    <item>
      <title>Docs: Data Pipelines Details</title>
      <link>https://tibcosoftware.github.io/labs-air/docs/userguide/datapipelines/</link>
      <pubDate>Mon, 25 May 2020 12:36:01 -0400</pubDate>
      
      <guid>https://tibcosoftware.github.io/labs-air/docs/userguide/datapipelines/</guid>
      <description>
        
        
        &lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;TIBCO Project AIR enables users to configure flows/business logic with data from edge devices.
Users can configure a Data Pipeline (Data Flow) to sequence, filter, stream data and specify a data store based on your business logic.
A typical pipeline configuration consists of activities that define the messaging protocol to receive data, define operations on the data (filtering, streaming, inferencing, rules) and the data stores.
This section will guide you through all the steps required to  create data pipelines.&lt;/p&gt;
&lt;h2 id=&#34;architecture-overview&#34;&gt;Architecture Overview&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;./air_pipelne_architecture.png&#34; alt=&#34;Pipeline Architecture Overview&#34;&gt;&lt;/p&gt;
&lt;p&gt;Every AIR deployment consist of edge components (devices, edge framework), as well as components that can be colocated at the edge, on premise, or on a private or public clooud.
Devices interact with whole AIR infrastructure through Edgex adapters providing the device&amp;rsquo;s required communication protocol and data standard.  Data traverse through the Edgex layers using an internal Edgex messaging protocol (i.e. MQTT).  Data is standardized and converted into a common schema which can then be used by any application at the Edgex Service Layer (.ie. AIR Pipelines).
AIR Pipelines can be configured from the provided UI which can be running locally or remotely. Pipelines are configured to recieve/subscribe standardized data from devices using the provided Edgex internal messaging protocol, filter, stream, infer, apply rules to the data and then publish the data to other applications.
Data can be published to AIR applications or other pipelines running at the edge or at the cloud.  Applications can use the messaging protocol (i.e. MQTT) provided by AIR infrastructure.
Once the pipelines are configured, pipelines are converted into Flogo Applications, compiled to the desired platform, conteinerized and then deployed.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;h4 id=&#34;prerequisite-1-device-groups-configuration&#34;&gt;Prerequisite 1: Device Groups Configuration&lt;/h4&gt;
&lt;p&gt;Before you begin, make sure the messaging protocols, data stores and models configuration for device groups have been configured. See &lt;a href=&#34;../../tutorials&#34;&gt;here&lt;/a&gt;.
See Configuring Device Groups.&lt;/p&gt;
&lt;h2 id=&#34;adding-data-pipelines&#34;&gt;Adding Data Pipelines&lt;/h2&gt;
&lt;h4 id=&#34;step-1-open-pipeline-editor&#34;&gt;Step 1: Open Pipeline Editor&lt;/h4&gt;
&lt;p&gt;From the Gateways page, select the Device Group you want to configure and click Pipeline Editor Icon.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./air_gateway_pipeline.png&#34; alt=&#34;Gateway Pipeline Config image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-2-the-pipelines-editor-page-should-be-displayed&#34;&gt;Step 2: The Pipelines Editor page should be displayed.&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_pipeline.png&#34; alt=&#34;Pipeline Config image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-3-subscribe-to-device-events&#34;&gt;Step 3: Subscribe to device events&lt;/h4&gt;
&lt;p&gt;On the editor canvas, right click and select the Data Subscriber activity.&lt;/p&gt;
&lt;p&gt;Most data pipelines start subscribing to events coming from devices. The Data Subscriber activity allows users to select the source of the device data.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_pipeline_1.png&#34; alt=&#34;Subscriber image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-4-configure-data-subscriber&#34;&gt;Step 4: Configure Data Subscriber&lt;/h4&gt;
&lt;p&gt;On the activity configuration panel, select and review the messaging protocol&lt;/p&gt;
&lt;p&gt;All the messaging protocols that have previously been configured in the Device Groups Configuration will be available for selection.  Select the source for device events.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_pipeline_2.png&#34; alt=&#34;Subscriber Config image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-5-filter-device-data-optional&#34;&gt;Step 5: Filter device data (Optional)&lt;/h4&gt;
&lt;p&gt;Select the devices to filter by selecting the Filter Activity.&lt;/p&gt;
&lt;p&gt;Data can be filtered from going through the pipeline. Right click on the editor canvas and select Filters.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_pipeline_3.png&#34; alt=&#34;Filter image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-6-configure-filter-activity&#34;&gt;Step 6: Configure filter activity&lt;/h4&gt;
&lt;p&gt;On the activity configuration panel, select device and resource (sensors) data to be filtered. Only the sensor data/resources non-selected in the list will be propagated through the pipeline. Connect activities by selecting the connection ports.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_pipeline_4.png&#34; alt=&#34;Filter Config image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-7-publish-device-data&#34;&gt;Step 7: Publish device data&lt;/h4&gt;
&lt;p&gt;On the editor canvas, right click and select the Data Publisher activity.&lt;/p&gt;
&lt;p&gt;Device data can be published to any messaging protocol that has been previously configured in the Device Groups connection pages.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_pipeline_5.png&#34; alt=&#34;Publisher image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-8-configure-data-publisher&#34;&gt;Step 8: Configure Data Publisher&lt;/h4&gt;
&lt;p&gt;On the activity configuration panel, select and review the messaging protocol&lt;/p&gt;
&lt;p&gt;All the messaging protocols that have previously been configured in the Device Groups Configuration will be available for selection.  Select the destination for device events.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_pipeline_6.png&#34; alt=&#34;Publisher Config image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-9-name-and-save-data-pipeline&#34;&gt;Step 9: Name and Save Data Pipeline.&lt;/h4&gt;
&lt;p&gt;After entering pipeline name, deployment target and deployer type, save the pipeline configuration.  The configuration can then be deployed to a Kubernetes cluster either local or on the cloud.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./air_config_pipeline_7.png&#34; alt=&#34;Pipeline Save image&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;deploying-data-pipelines&#34;&gt;Deploying Data Pipelines&lt;/h2&gt;
&lt;p&gt;Once data pipelines have been configured, they can be deployed dynamically to Kubernetes cluster running locally or on the cloud.&lt;/p&gt;
&lt;h4 id=&#34;step-1-select-the-desired-pipeline-from-the-pipelines-table-and-then-click--deploy-pipeline&#34;&gt;Step 1: Select the desired pipeline from the Pipelines table and then click  Deploy Pipeline&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_deploy_pipeline_1.png&#34; alt=&#34;Pipeline Deploy Select image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-2-the-pipeline-is-deployed-and-should-show-the-status-as-readydeployed&#34;&gt;Step 2: The pipeline is deployed and should show the Status as Ready/Deployed&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_deploy_pipeline_2.png&#34; alt=&#34;Pipeline Deploy Result image&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;verifying-data-pipelines-deployment&#34;&gt;Verifying Data Pipelines Deployment&lt;/h2&gt;
&lt;p&gt;After a pipeline is deployed from the UI, a Docker container is started in the deployment target machine.
There are several ways to verify the container is up and running. In this section we will use Docker Desktop to verify and inspect the deployed contianer.&lt;/p&gt;
&lt;h4 id=&#34;step-1-note-id-of-deployed-pipeline&#34;&gt;Step 1: Note Id of deployed Pipeline&lt;/h4&gt;
&lt;p&gt;After the pipeline is deployed, a new entry will be shown in the pipelines table.  Note the id of the pipeline as that will be used to identify the running container.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./air_deploy_verify_1.png&#34; alt=&#34;Verify Pipeline Deploy image1&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-2-open-docker-dashboard&#34;&gt;Step 2: Open Docker Dashboard&lt;/h4&gt;
&lt;p&gt;Open Docker Dashboard UI and select the Containers/Apps tab. A list of all running containers is shown.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./air_deploy_verify_2.png&#34; alt=&#34;Verify Pipeline Deploy image2&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-3-inspect-container&#34;&gt;Step 3: Inspect Container&lt;/h4&gt;
&lt;p&gt;From the list of containers, select and open the container matching the Id noted in Step1.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./air_deploy_verify_3.png&#34; alt=&#34;Verify Pipeline Deploy image3&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-4-viewing-container-logs&#34;&gt;Step 4: Viewing Container Logs&lt;/h4&gt;
&lt;p&gt;After container is selected, select the LOGS tab to view the container logs.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./air_deploy_verify_4.png&#34; alt=&#34;Verify Pipeline Deploy image4&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-5-viewing-container-stats&#34;&gt;Step 5: Viewing Container Stats&lt;/h4&gt;
&lt;p&gt;From selected container panel, select the STATS tab to review container&amp;rsquo;s cpu usage, memory usage, etc.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;./air_deploy_verify_5.png&#34; alt=&#34;Verify Pipeline Deploy image5&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;updeploying-data-pipelines&#34;&gt;Updeploying Data Pipelines&lt;/h2&gt;
&lt;p&gt;If data from a device is not longer required or if needs to be modified, you can undeploy the pipeline.  Undeploying will remove the engine processing the data from the Kubernetes cluster.&lt;/p&gt;
&lt;h4 id=&#34;step-1-select-the-desired-pipeline-from-the-pipelines-table-and-then-click-undeploy-pipeline&#34;&gt;Step 1: Select the desired pipeline from the Pipelines table and then click Undeploy Pipeline&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_undeploy_pipeline_1.png&#34; alt=&#34;Pipeline Undeploy Select image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-2-the-pipeline-is-undeployed-and-should-show-the-status-as-undeployedsaved&#34;&gt;Step 2: The pipeline is undeployed and should show the Status as Undeployed/Saved&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_undeploy_pipeline_2.png&#34; alt=&#34;Pipeline Undeploy Final image&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;deleting-data-pipelines&#34;&gt;Deleting Data Pipelines&lt;/h2&gt;
&lt;p&gt;If data pipelines are not longer required, you can delete the pipeline. Notice that deployed pipelines can&amp;rsquo;t be deleted.  They need to be undeployed first.&lt;/p&gt;
&lt;h4 id=&#34;step-1-select-the-desired-pipeline-from-the-pipelines-table-and-then-click--delete-pipeline&#34;&gt;Step 1: Select the desired pipeline from the Pipelines table and then click  Delete Pipeline&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;./air_delete_pipeline_1.png&#34; alt=&#34;Pipeline Delete Select image&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;step-2-the-pipeline-is-deleted-and-should-not-appear-in-the-pipelines-table&#34;&gt;Step 2: The pipeline is deleted and should not appear in the Pipelines table.&lt;/h4&gt;

      </description>
    </item>
    
  </channel>
</rss>
